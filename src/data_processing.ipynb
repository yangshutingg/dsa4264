{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the large dataset, read in the data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10000\n",
    "chunks = pd.read_csv('../data/Reddit-Threads_2020-2021.csv', chunksize=chunk_size)\n",
    "chunks2 = pd.read_csv('../data/Reddit-Threads_2022-2023.csv', chunksize=chunk_size)\n",
    "data_2021 = pd.concat(chunk for chunk in chunks)\n",
    "data_2223 = pd.concat(chunk for chunk in chunks2)\n",
    "combined_data = pd.concat([data_2021, data_2223]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = combined_data[combined_data.isna().any(axis=1)]\n",
    "# view missing_values\n",
    "# missing_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "combined_data = combined_data.dropna()\n",
    "# filter out deleted/removed comments\n",
    "combined_data = combined_data[~combined_data['text'].isin([\"[deleted]\", \"[removed]\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract `yearmonth` from `timestamp` for temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "combined_data['yearmonth'] = combined_data['timestamp'].dt.to_period('M')\n",
    "\n",
    "# order by timestamp\n",
    "combined_data = combined_data.sort_values(by='timestamp').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract thread's `title` for each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['title'] = combined_data['link'].apply(lambda x: x.split('/')[5] if isinstance(x, str) else None)\n",
    "combined_data['title'] = combined_data['title'].str.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `index` as primary key for easier processing of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['index'] = combined_data.index\n",
    "# view the structure of combined_data\n",
    "# combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv('../data/combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine text data with toxicity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/combined_data.csv')\n",
    "\n",
    "hatebert_scores = pd.read_csv('../data/hatebert_scores.csv')\n",
    "hatexplain_scores = pd.read_csv('../data/hateXplain_scores.csv')\n",
    "toxicbert_scores = pd.read_csv('../data/toxicbert_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average of the 3 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the three scores with the combined_data on `index` column\n",
    "scores = pd.merge(hatebert_scores, hatexplain_scores, toxicbert_scores, on='index', suffixes=('_hatebert', '_hatexplain', '_toxicbert'))\n",
    "text_scores = combined_data.merge(scores, on='index', how='left')\n",
    "\n",
    "# calculate the average of the three scores\n",
    "text_scores['average_toxicity_score'] = text_scores[['toxicity_score_hatebert', 'toxicity_score_hatexplain', 'toxicity_score_toxicbert']].mean(axis=1)\n",
    "\n",
    "# rename columns\n",
    "text_scores = text_scores.rename(columns={'toxicity_score_hatebert': 'hatebert_toxicity_score', 'toxicity_score_hatexplain': 'hateXplain_toxicity_score', 'toxicity_score_toxicbert': 'toxicbert_toxicity_score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "text_scores.to_csv('../data/combined_data_scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
